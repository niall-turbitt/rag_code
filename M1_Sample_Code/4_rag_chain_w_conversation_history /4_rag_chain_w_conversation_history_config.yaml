# Get the following params from the final cell of 3_pdf_rag/3_load_pdf_to_vector_index
vector_search_endpoint_name: "dbdemos_vs_endpoint"
vector_search_index: "niall_dev.fox_sports.gold_nfl_draft_chunked_index"
# These must be set to use the Review App
vector_search_schema:
  primary_key: chunk_id
  chunk_text: chunked_text
  document_source: doc_uri
vector_search_parameters:
  k: 3
chunk_template: "`{chunk_text}`\n"
chat_endpoint: "databricks-dbrx-instruct"
chat_prompt_template: "You are a trusted assistant that helps answer questions about Sports-related questions on Fox Sports. If you do not know the answer to a question, you truthfully say you do not know.  Here is some context which might or might not help you answer: {context}.  Answer directly, do not repeat the question, do not start with something like: the answer to the question, do not add AI in front of your answer, do not say: here is the answer, do not mention the context or the question. Based on this history and context, answer this question: {question}."
chat_prompt_template_variables:
  - "context"
  - "question"
chat_endpoint_parameters:
  temperature: 0.01
  max_tokens: 500
query_rewriter_prompt_template: >
  "Based on the chat history below, we want you to generate a query for an external data source to retrieve relevant documents so that we can better answer the question. The query should be in natual language. The external data source uses similarity search to search for relevant documents in a vector space. So the query should be similar to the relevant documents semantically. Answer with only the query. Do not add explanation.
  
  Chat history: {chat_history}

  Question: {question}"
query_rewriter_prompt_template_variables:
  - "chat_history"
  - "question"